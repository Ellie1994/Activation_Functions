# Activation_Functions
The code is additional to the article on [my blog](https://siegel.work/blog/) and presents some popular **activation functions**. Sigmoid and tanH became less popular in last years. On the other hand, ReLu (*Rectified Linear Unit*) gained a lot popularity recently.

The link to the full article on [activation functions](https://siegel.work/blog/ActivationFunctions/).


![**Sigmoid Function**](sigmoid.png)


![**tanH Function**](tanH.png)


![**ReLu Function**](relu.png)
